{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chrome_path = \"C:\\\\chromedriver\\\\chromedriver.exe\"\n",
    "#css_selector = '[name = \"AIER Event\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_websites(csv_path):\n",
    "    name_to_websites = {}\n",
    "    f = open(csv_path, 'r')\n",
    "    headers = f.readline().split(',')\n",
    "    website_index = -1\n",
    "    university_index = -1\n",
    "    for index, header in enumerate(headers):\n",
    "        if 'website' in header.lower():\n",
    "            website_index = index\n",
    "            break\n",
    "    for index, header in enumerate(headers):\n",
    "        if 'university' in header.lower() or 'college' in header.lower() or 'name' in header.lower():\n",
    "            university_index = index\n",
    "            break\n",
    "    if website_index == -1:\n",
    "        raise Exception('No websites found')\n",
    "    for row in f:\n",
    "        entries = row.split(',')\n",
    "        website = entries[website_index].replace('\\n', '').strip()\n",
    "        university = entries[university_index].replace('\\n', '').strip()\n",
    "        name_to_websites[university] = website\n",
    "    f.close()\n",
    "    return name_to_websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fake_File:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def write(self, message):\n",
    "        print(message.replace('\\n', ''))\n",
    "    def close(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#websites = load_websites(\"C:\\\\Selenium_Downloads\\\\Standard Event Scraping Test Websites - Sheet1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_script(browser, script):\n",
    "        try:\n",
    "            browser.execute_script(script)\n",
    "            return True\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_recursive(name, website, css_selector, log_file, chrome_path, wait_time = 1, max_recursions = 100):\n",
    "    def _lost_file(exception):\n",
    "        nonlocal log_file\n",
    "        log_file = Fake_File()\n",
    "        log_file.write('\\tLost connection to file')\n",
    "        log_file.write('\\tPrinting logs to command line')\n",
    "        log_file.write('\\t' + str(exception))\n",
    "    try:\n",
    "        log_file.write('Starting scraping of ' + name + '\\n')\n",
    "        log_file.write('\\tOpening browser\\n')\n",
    "    except Exception as e:\n",
    "        _lost_file(e)\n",
    "    try:\n",
    "        browser = Chrome(chrome_path)\n",
    "        try:\n",
    "            log_file.write('\\t\\tSuccessfullty opened browser\\n')\n",
    "        except Exception as e:\n",
    "            _lost_file(e)\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            log_file.write('\\t\\t!!!Failed to open browser, check path to chrome driver\\n')\n",
    "            log_file.write('\\t\\t' + str(e) + '\\n')\n",
    "            log_file.write('\\t\\tEnding scraping of ' + name + '\\n')\n",
    "        except Excpetion as e2:\n",
    "            _lost_file(e2)\n",
    "        browser.close()\n",
    "        return\n",
    "    log_file.write('\\tAttempting to open ' + website + '\\n')\n",
    "    try:\n",
    "        browser.get(website)\n",
    "        try:\n",
    "            log_file.write('\\t\\tSuccesfully opened ' + website + '\\n')\n",
    "        except Exception as e:\n",
    "            _lost_file(e)\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            log_file.write('\\t\\t!!!Failed to open ' + website + ', check URL and internet connection\\n')\n",
    "            log_file.write('\\t\\t' + str(e) + '\\n')\n",
    "            log_file.write('\\t\\tEnding scraping of ' + name + '\\n')\n",
    "        except Excpetion as e2:\n",
    "            _lost_file(e2)\n",
    "        browser.close()\n",
    "        return\n",
    "    url_to_current_link = {\n",
    "        browser.current_url : 0\n",
    "    }\n",
    "    def _find_links_and_click(recursions):\n",
    "        if recursions <= 0:\n",
    "            try:\n",
    "                log_file.write('\\t\\t!!?Max recursions reached\\n')\n",
    "            except Exception as e:\n",
    "                _lost_file(e)\n",
    "            return\n",
    "        if browser.current_url == 'data:,':\n",
    "            try:\n",
    "                log_file.write('\\t\\tAll links found\\n')\n",
    "            except Exception as e:\n",
    "                _lost_file(e)\n",
    "            return\n",
    "        link_index = url_to_current_link[browser.current_url]\n",
    "        try:\n",
    "            log_file.write('\\t\\tLooking for event links on ' + browser.current_url + ' by ' + css_selector + '\\n')\n",
    "        except Exception as e:\n",
    "            _lost_file(e)\n",
    "        try:\n",
    "            links =  WebDriverWait(browser, 3).until(lambda d: d.find_elements_by_css_selector(css_selector))\n",
    "            try:\n",
    "                log_file.write('\\t\\t\\tFound ' + str(len(links)) + ' matching links\\n')\n",
    "            except Exception as e:\n",
    "                _lost_file(e)\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                log_file.write('\\t\\t\\t!??Failed to find any links\\n')\n",
    "                log_file.write('\\t\\t\\t' + str(e) + '\\n')\n",
    "                log_file.write('\\t\\t\\tGoing back\\n')\n",
    "            except Exception as e2:\n",
    "                _lost_file(e)\n",
    "            browser.back()\n",
    "            _find_links_and_click()\n",
    "        if len(links) > link_index:\n",
    "            url_to_current_link[browser.current_url] += 1\n",
    "            try:\n",
    "                log_file.write('\\t\\tAttempting to click on link ' + str(link_index) + ' on ' + browser.current_url + '\\n')\n",
    "            except Exception as e:\n",
    "                _lost_file(e)\n",
    "            try:\n",
    "                links[link_index].click()\n",
    "                time.sleep(wait_time)\n",
    "                try:\n",
    "                    log_file.write('\\t\\t\\tSuccessfully clicked on link\\n')\n",
    "                except Exception as e:\n",
    "                    _lost_file(e)\n",
    "            except Exception as e:\n",
    "                try:\n",
    "                    log_file.write('\\t\\t\\t!??Failed to click on link\\n')\n",
    "                    log_file.write('\\t\\t\\t' + str(e) + '\\n')\n",
    "                    log_file.write('\\t\\t\\tAttempting to click link using javascript\\n')\n",
    "                except Exception as e2:\n",
    "                    _lost_file(e2)\n",
    "                try:\n",
    "                    javaScript = \"document.querySelectorAll('\" + css_selector + \"')[\" + str(link_index) + \"].click();\"\n",
    "                    WebDriverWait(browser, 5).until(lambda d: execute_script(browser, javaScript))\n",
    "                    try:\n",
    "                        log_file.write('\\t\\t\\t\\tSuccessfully clicked link\\n')\n",
    "                    except Exception as e2:\n",
    "                        _lost_file(e2)\n",
    "                except Exception as e2:\n",
    "                    try:\n",
    "                        log_file.write('\\t\\t\\t\\t!!?Failed to click link\\n')\n",
    "                        log_file.write('\\t\\t\\t\\t' + str(e2) + '\\n')\n",
    "                        log_file.write('\\t\\t\\t\\tContinuing\\n')\n",
    "                    except Exception as e3:\n",
    "                        _lost_file(e3)\n",
    "                    _find_links_and_click(recursions - 1)\n",
    "            if browser.current_url not in url_to_current_link.keys():\n",
    "                try:\n",
    "                    log_file.write('\\t\\t' + browser.current_url + ' not yet discovered\\n')\n",
    "                    log_file.write('\\t\\tAdding new URL\\n')\n",
    "                except Excetion as e:\n",
    "                    _lost_file(e)\n",
    "                url_to_current_link[browser.current_url] = 0\n",
    "        else:\n",
    "            try:\n",
    "                log_file.write('\\t\\tNo more links on this page\\n')\n",
    "                log_file.write('\\t\\tGoing back\\n')\n",
    "            except Exception as e:\n",
    "                _lost_file(e)\n",
    "            browser.back()\n",
    "        _find_links_and_click(recursions - 1)\n",
    "    _find_links_and_click(max_recursions)\n",
    "    try:\n",
    "        log_file.write('\\tScraping of ' + name + ' finished\\n')\n",
    "    except Excpetion as e:\n",
    "        _lost_file(e)\n",
    "    browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# websites = {\n",
    "#     'test' : 'https://alexanderhamiltonwaswright.com/index.html'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all(log_file_path, websites, css_selector, chrome_path, wait_time, max_recursions):\n",
    "    try:\n",
    "        now = datetime.now()\n",
    "        f = open(log_file_path + 'AIER Event Scraping Utility Started at ' + now.strftime(\"%d-%m-%Y @ %H;%M;%S\") +'.log','a')\n",
    "    except Exception as e:\n",
    "        print('!!!?Failed to create log file')\n",
    "        print('Printing log file to console')\n",
    "        print(e)\n",
    "        f = Fake_File()\n",
    "    for name, website in websites.items():\n",
    "        try:\n",
    "            scrape_recursive(name, website, css_selector, f, chrome_path, wait_time, max_recursions)\n",
    "        except Exception as e:\n",
    "            f.write('!!!Scraping of ' + name + ' failed\\n')\n",
    "            f.write(str(e) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 5 matching links\n",
      "\t\tAttempting to click on link 0 on https://alexanderhamiltonwaswright.com/index.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/index.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 5 matching links\n",
      "\t\tAttempting to click on link 1 on https://alexanderhamiltonwaswright.com/index.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\thttps://alexanderhamiltonwaswright.com/recursive0.html not yet discovered\n",
      "\t\tAdding new URL\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive0.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 5 matching links\n",
      "\t\tAttempting to click on link 0 on https://alexanderhamiltonwaswright.com/recursive0.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive0.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 5 matching links\n",
      "\t\tAttempting to click on link 1 on https://alexanderhamiltonwaswright.com/recursive0.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive0.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 5 matching links\n",
      "\t\tAttempting to click on link 2 on https://alexanderhamiltonwaswright.com/recursive0.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive0.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 5 matching links\n",
      "\t\tAttempting to click on link 3 on https://alexanderhamiltonwaswright.com/recursive0.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive0.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 5 matching links\n",
      "\t\tAttempting to click on link 4 on https://alexanderhamiltonwaswright.com/recursive0.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive0.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 5 matching links\n",
      "\t\tNo more links on this page\n",
      "\t\tGoing back\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/index.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 5 matching links\n",
      "\t\tAttempting to click on link 2 on https://alexanderhamiltonwaswright.com/index.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/index.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 5 matching links\n",
      "\t\tAttempting to click on link 3 on https://alexanderhamiltonwaswright.com/index.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\thttps://alexanderhamiltonwaswright.com/back-test.html not yet discovered\n",
      "\t\tAdding new URL\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/back-test.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 1 matching links\n",
      "\t\tAttempting to click on link 0 on https://alexanderhamiltonwaswright.com/back-test.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/index.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 5 matching links\n",
      "\t\tAttempting to click on link 4 on https://alexanderhamiltonwaswright.com/index.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\thttps://alexanderhamiltonwaswright.com/recursive1.html not yet discovered\n",
      "\t\tAdding new URL\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive1.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 4 matching links\n",
      "\t\tAttempting to click on link 0 on https://alexanderhamiltonwaswright.com/recursive1.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive1.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 4 matching links\n",
      "\t\tAttempting to click on link 1 on https://alexanderhamiltonwaswright.com/recursive1.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\thttps://alexanderhamiltonwaswright.com/recursive1-0.html not yet discovered\n",
      "\t\tAdding new URL\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive1-0.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 1 matching links\n",
      "\t\tAttempting to click on link 0 on https://alexanderhamiltonwaswright.com/recursive1-0.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive1-0.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 1 matching links\n",
      "\t\tNo more links on this page\n",
      "\t\tGoing back\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive1.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 4 matching links\n",
      "\t\tAttempting to click on link 2 on https://alexanderhamiltonwaswright.com/recursive1.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive1.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 4 matching links\n",
      "\t\tAttempting to click on link 3 on https://alexanderhamiltonwaswright.com/recursive1.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\thttps://alexanderhamiltonwaswright.com/recursive1-1.html not yet discovered\n",
      "\t\tAdding new URL\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive1-1.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 1 matching links\n",
      "\t\tAttempting to click on link 0 on https://alexanderhamiltonwaswright.com/recursive1-1.html\n",
      "\t\t\tSuccessfully clicked on link\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive1-1.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 1 matching links\n",
      "\t\tNo more links on this page\n",
      "\t\tGoing back\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/recursive1.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 4 matching links\n",
      "\t\tNo more links on this page\n",
      "\t\tGoing back\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/index.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 5 matching links\n",
      "\t\tNo more links on this page\n",
      "\t\tGoing back\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/back-test.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 1 matching links\n",
      "\t\tNo more links on this page\n",
      "\t\tGoing back\n",
      "\t\tLooking for event links on https://alexanderhamiltonwaswright.com/index.html by [name = \"AIER Event\"]\n",
      "\tLost connection to file\n",
      "\tPrinting logs to command line\n",
      "name 'a' is not defined\n",
      "\t\t\tFound 5 matching links\n",
      "\t\tNo more links on this page\n",
      "\t\tGoing back\n",
      "\t\tAll links found\n",
      "\tScraping of test finished\n"
     ]
    }
   ],
   "source": [
    "#scrape_all(\"C:\\Selenium_Downloads\\\\\", websites, '[name = \"AIER Event\"]', \"C:\\\\chromedriver\\\\chromedriver.exe\", 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_chrome_path(path):\n",
    "    browser = Chrome(path)\n",
    "    browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_log_file_path(path):\n",
    "    f = open(path + 'test.txt', 'a')\n",
    "    f.close()\n",
    "    os.remove(path + 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def command_line_interface():\n",
    "    print('Enter css selector:')\n",
    "    time.sleep(0.25)\n",
    "    css_selector = input()\n",
    "    while True:\n",
    "        print('Enter path to .csv with instititute name and website:')\n",
    "        csv_path = input()\n",
    "        csv_path = csv_path.replace('\"','')\n",
    "        print('Loading websites...')\n",
    "        try:\n",
    "            websites = load_websites(csv_path)\n",
    "            print('Websites loaded')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print('Website loading failed')\n",
    "            print(e)\n",
    "    while True:\n",
    "        print('Enter path to chromedriver:')\n",
    "        chrome_path = input()\n",
    "        chrome_path = chrome_path.replace('\"','')\n",
    "        try:\n",
    "            check_chrome_path(chrome_path)\n",
    "            print('Chromedriver loaded')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print('Chromedriver loading failed')\n",
    "            print(e)\n",
    "    while True:\n",
    "        print('Enter path for log file:')\n",
    "        log_file_path = input()\n",
    "        log_file_path = log_file_path.replace('\"','') + '\\\\'\n",
    "        try:\n",
    "            check_log_file_path(log_file_path)\n",
    "            print('Log file path accepted')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print('Log file rejected')\n",
    "            print(e)\n",
    "    while True:\n",
    "        print('Enter wait time between click (in seconds, must be a number):')\n",
    "        try:\n",
    "            wait_time = float(input())\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print('Input must be a number')\n",
    "            print(e)\n",
    "    while True:\n",
    "        print('Enter maximum number of clicks per website (must be an integer):')\n",
    "        try:\n",
    "            max_recursions = int(input())\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print('Input must be an integer')\n",
    "    print('Running program...')\n",
    "    scrape_all(log_file_path, websites, css_selector, chrome_path, wait_time, max_recursions)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter css selector:\n",
      "[name = \"AIER Event\"]\n",
      "Enter path to .csv with instititute name and website:\n",
      "\"C:\\Selenium_Downloads\\Standard Event Scraping Test Websites - Sheet1.csv\"\n",
      "Loading websites...\n",
      "Websites loaded\n",
      "Enter path to chromedriver:\n",
      "\"C:\\\\chromedriver\\\\chromedriver.exe\"\n",
      "Chromedriver loaded\n",
      "Enter path for log file:\n",
      "\"C:\\Selenium_Downloads\"\n",
      "Log file path accepted\n",
      "Enter wait time between click (in seconds, must be a number):\n",
      "1\n",
      "Enter maximum number of clicks per website (must be an integer):\n",
      "100\n",
      "Running program ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "command_line_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
